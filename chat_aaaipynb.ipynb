{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1-A7ZDavtK595E7bT0IPmPzsdpEeCsAwD",
      "authorship_tag": "ABX9TyMDuw/b5ejbz4qywa63tlCW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Masterhuthiu/TypeScript_BackEnd/blob/main/chat_aaaipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain-core langchain-community ctransformers\n"
      ],
      "metadata": {
        "id": "h3qt7lu2tfPu"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf -O mistral.gguf\n"
      ],
      "metadata": {
        "id": "74vs7GNsv4av"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sxZYce_ewWjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import CTransformers\n",
        "\n",
        "llm = CTransformers(\n",
        "    model=\"mistral.gguf\",\n",
        "    model_type=\"mistral\",\n",
        "    max_new_tokens=256,\n",
        "    temperature=0.2\n",
        ")\n"
      ],
      "metadata": {
        "id": "o2vrgUPVwCju"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableSequence\n"
      ],
      "metadata": {
        "id": "vxY1kto8wXnW"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=\"Giải thích dễ hiểu về: {topic}\"\n",
        ")\n",
        "\n",
        "chain = RunnableSequence(prompt | llm)\n"
      ],
      "metadata": {
        "id": "4W2puPgcwbXX"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"topic\": \"Transformer neural networks\"})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "B9lN0MNNwefm",
        "outputId": "1790d25a-d394-4dac-c6b1-9162c779d39a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' and their advantages over recurrent neural networks\\n\\nTransformer neural networks là một loại neural network mới được giới thiệu bởi Vaswani et al. trong bài báo \"Attention is All You Need\" năm 2017, họ đã chính thức hủy dẫn ý tính của Recurrent Neural Networks (RNN) và Long Short-Term Memory (LSTM) trong việc xử lý mạng ngôn ngữ và các loại data serial.\\n\\nTransformer neural networks sử dụng Mechanism \"Attention\" để tự quyết định rất quan trong những phần xuống tiếp theo cần được focussed hoặc đánh giá cao hơn. Riêng Recurrent Neural Networks (RNN) và Long Short-Term Memory (LSTM) s'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}